{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burgers Equation \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(2, 20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20, 1)\n",
    "            \n",
    "        )\n",
    "    def forward(self, x, t):\n",
    "        inputs = torch.cat([x, t], dim = 1)\n",
    "        u = self.hidden(inputs)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the pde residual function\n",
    "def pde_residual(x, t, model, nu = 0.01):\n",
    "    #enable gradients for x and t so we can compute their derivatives\n",
    "    x.requires_grad = True\n",
    "    t.requires_grad = True\n",
    "    \n",
    "    u = model(x, t) #predict u from the model\n",
    "    u_t = torch.autograd.grad(u, t, torch.ones_like(u), create_graph=True)[0]  \n",
    "    u_x = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]  \n",
    "    u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u_x), create_graph=True)[0]  \n",
    "\n",
    "    \n",
    "    residual = u_t + u * u_x - nu* u_xx  #residual of burger's equation\n",
    "    return residual\n",
    "\n",
    "#initial and boundary condiitons\n",
    "def initial_condition(x):\n",
    "    return -torch.sin(np.pi * x)\n",
    "\n",
    "def boundary_condition(x, t):\n",
    "    return torch.zeros_like(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the training data\n",
    "x = torch.linspace(-1, 1, 200).view(-1, 1)  #spatial points\n",
    "t = torch.linspace(0, 1, 100).view(-1, 1)  #temporal points\n",
    "x_train, t_train = torch.meshgrid(x.squeeze(), t.squeeze(), indexing = 'xy')\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "t_train = t_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "model = PINN()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-1, 1, 200).view(-1, 1)  #spatial points\n",
    "t = torch.linspace(0, 1, 100).view(-1, 1)  #temporal points\n",
    "x_train, t_train = torch.meshgrid(x.squeeze(), t.squeeze(), indexing = 'xy')\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "t_train = t_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/12000], Loss: 0.9652\n",
      "Epoch [501/12000], Loss: 0.0109\n",
      "Epoch [1001/12000], Loss: 0.0025\n",
      "Epoch [1501/12000], Loss: 0.0013\n",
      "Epoch [2001/12000], Loss: 0.0008\n",
      "Epoch [2501/12000], Loss: 0.0010\n",
      "Epoch [3001/12000], Loss: 0.0024\n",
      "Epoch [3501/12000], Loss: 0.0006\n",
      "Epoch [4001/12000], Loss: 0.0017\n",
      "Epoch [4501/12000], Loss: 0.0030\n",
      "Epoch [5001/12000], Loss: 0.0023\n",
      "Epoch [5501/12000], Loss: 0.0003\n",
      "Epoch [6001/12000], Loss: 0.0017\n",
      "Epoch [6501/12000], Loss: 0.0001\n",
      "Epoch [7001/12000], Loss: 0.0002\n",
      "Epoch [7501/12000], Loss: 0.0002\n",
      "Epoch [8001/12000], Loss: 0.0001\n",
      "Epoch [8501/12000], Loss: 0.0001\n",
      "Epoch [9001/12000], Loss: 0.0001\n",
      "Epoch [9501/12000], Loss: 0.0001\n",
      "Epoch [10001/12000], Loss: 0.0002\n",
      "Epoch [10501/12000], Loss: 0.0007\n",
      "Epoch [11001/12000], Loss: 0.0008\n",
      "Epoch [11501/12000], Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 12000\n",
    "for each in range(num_epochs): \n",
    "    model.train()\n",
    "    \n",
    "    # Compute initial condition loss\n",
    "    u_pred = model(x, torch.zeros_like(x)) \n",
    "    u_true = initial_condition(x)\n",
    "    loss_ic = torch.mean((u_pred - u_true)**2)\n",
    "    \n",
    "    # Compute boundary condition loss\n",
    "    u_pred_left = model(torch.full_like(t, -1), t) # u(-1, t)\n",
    "    u_pred_right = model(torch.full_like(t, 1), t) # u(1, t)\n",
    "    loss_bc = torch.mean((u_pred_left - boundary_condition(torch.full_like(t, -1), t))**2) + \\\n",
    "              torch.mean((u_pred_right - boundary_condition(torch.full_like(t, 1), t))**2)\n",
    "    \n",
    "    # Compute PDE residual loss\n",
    "    residual = pde_residual(x_train, t_train, model)\n",
    "    loss_pde = torch.mean(residual**2) \n",
    "    \n",
    "    loss = loss_ic + loss_bc + loss_pde\n",
    "    \n",
    "    # Backpropagation and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#     print(\"Hi\")\n",
    "   \n",
    "    if each % 500 == 0:\n",
    "        print(f'Epoch [{each + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
