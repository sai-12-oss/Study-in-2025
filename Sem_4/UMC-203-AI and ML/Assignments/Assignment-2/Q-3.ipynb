{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Linear Regression - Ordinary Least Squares(OLS) and Ridge Regression(RR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task-1 : Query the oracle to obtain D_train1 , D_train2 , D_test1 , and D_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Oracle_Assignment_2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "data_1 = Oracle_Assignment_2.q3_linear_1(23627)\n",
    "data_2 = Oracle_Assignment_2.q3_linear_2(23627)\n",
    "(X_train_1,y_train_1,X_test_1,y_test_1) = data_1\n",
    "(X_train_2,y_train_2,X_test_2,y_test_2) = data_2\n",
    "X_train_1,y_train_1 = np.array(X_train_1),np.array(y_train_1)\n",
    "X_test_1,y_test_1 = np.array(X_test_1),np.array(y_test_1)\n",
    "X_train_2,y_train_2 = np.array(X_train_2),np.array(y_train_2)\n",
    "X_test_2,y_test_2 = np.array(X_test_2),np.array(y_test_2)\n",
    "D_1_train = (X_train_1, y_train_1)\n",
    "D_2_train = (X_train_2, y_train_2)\n",
    "D_1_test = (X_test_1, y_test_1)\n",
    "D_2_test = (X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task-2 : Compute weights using OLS and RR for D_train1 and D_train2 (use Lambda = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of weight vectors:\n",
      "w1_ols: (5, 1)\n",
      "w1_rr: (5, 1)\n",
      "w2_ols: (100, 1)\n",
      "w2_rr: (100, 1)\n"
     ]
    }
   ],
   "source": [
    "def Solve_OLS(X,y):\n",
    "    X_T = X.T  # Transpose of X\n",
    "    X_T_X = np.matmul(X_T, X)  # X^T X using matmul\n",
    "    X_T_y = np.dot(X_T, y)  # X^T y using dot\n",
    "    w = np.dot(np.linalg.inv(X_T_X), X_T_y)  # (X^T X)^(-1) (X^T y) using inverse and dot\n",
    "    return w\n",
    "def Solve_RR(X, y, lambda_=1.0):\n",
    "    n, d = X.shape  # Number of samples and features\n",
    "    X_T = X.T  # Transpose of X\n",
    "    X_T_X = np.matmul(X_T, X)  # X^T X\n",
    "    I = np.eye(d)  # d × d identity matrix\n",
    "    reg_term = n * lambda_ * I  # Regularization term\n",
    "    X_T_X_reg = X_T_X + reg_term  # X^T X + nλI\n",
    "    X_T_y = np.dot(X_T, y)  # X^T y\n",
    "    w = np.dot(np.linalg.inv(X_T_X_reg), X_T_y)  # (X^T X + nλI)^(-1) (X^T y)\n",
    "    return w\n",
    "def Compute_Weights(D1_train, D2_train):\n",
    "    # Unpack datasets\n",
    "    X1, y1 = D1_train\n",
    "    X2, y2 = D2_train\n",
    "\n",
    "    # Compute weights for D1_train\n",
    "    w1_ols = Solve_OLS(X1, y1)\n",
    "    w1_rr = Solve_RR(X1, y1, lambda_=1.0)\n",
    "\n",
    "    # Compute weights for D2_train\n",
    "    w2_ols = Solve_OLS(X2, y2)\n",
    "    w2_rr = Solve_RR(X2, y2, lambda_=1.0)\n",
    "\n",
    "    return w1_ols, w1_rr, w2_ols, w2_rr\n",
    "w1_ols, w1_rr, w2_ols, w2_rr = Compute_Weights(D_1_train, D_2_train)\n",
    "print(\"Shapes of weight vectors:\")\n",
    "print(f\"w1_ols: {w1_ols.shape}\")\n",
    "print(f\"w1_rr: {w1_rr.shape}\")\n",
    "print(f\"w2_ols: {w2_ols.shape}\")\n",
    "print(f\"w2_rr: {w2_rr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task-3 : Calculate MSE for w1_ols and w1_rr using D_1_train and MSE for w2_ols and w2_rr using D_2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for w1_ols on D_1_train: [0.03340458]\n",
      "MSE for w1_rr on D_1_train: [0.11333904]\n",
      "MSE for w2_ols on D_2_train: [7115.79566132]\n",
      "MSE for w2_rr on D_2_train: [2.90381334]\n"
     ]
    }
   ],
   "source": [
    "def Compute_MSE(X, y, w):\n",
    "    n = len(y)\n",
    "    y_pred = np.dot(X, w)  # Predictions: X w\n",
    "    residuals = y - y_pred  # y - ŷ\n",
    "    squared_residuals = residuals ** 2  # (y - ŷ)^2\n",
    "    mse = sum(squared_residuals) / n  # Mean of squared residuals\n",
    "    return mse\n",
    "\n",
    "X1, y1 = D_1_train\n",
    "X2, y2 = D_2_train\n",
    "\n",
    "# Calculate MSE for each weight vector\n",
    "mse_w1_ols = Compute_MSE(X1, y1, w1_ols)\n",
    "mse_w1_rr = Compute_MSE(X1, y1, w1_rr)\n",
    "mse_w2_ols = Compute_MSE(X2, y2, w2_ols)\n",
    "mse_w2_rr = Compute_MSE(X2, y2, w2_rr)\n",
    "\n",
    "# Print the results\n",
    "print(\"MSE for w1_ols on D_1_train:\", mse_w1_ols)\n",
    "print(\"MSE for w1_rr on D_1_train:\", mse_w1_rr)\n",
    "print(\"MSE for w2_ols on D_2_train:\", mse_w2_ols)\n",
    "print(\"MSE for w2_rr on D_2_train:\", mse_w2_rr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deliverabeles:\n",
    "\n",
    "2. Report MSE on D_1_train. Report w1_ols and w1_rr in the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for w1_ols on D_1_train: [0.03340458]\n",
      "MSE for w1_rr on D_1_train: [0.11333904]\n",
      "[[0.29247212]\n",
      " [0.22938018]\n",
      " [0.25741656]\n",
      " [0.37920109]\n",
      " [0.0631003 ]] [[0.10001808]\n",
      " [0.06957697]\n",
      " [0.08057619]\n",
      " [0.22592413]\n",
      " [0.01404171]]\n"
     ]
    }
   ],
   "source": [
    "w1_ols, w1_rr, w2_ols, w2_rr = Compute_Weights(D_1_train, D_2_train)\n",
    "X = D_1_train[0]\n",
    "y = D_1_train[1]\n",
    "w1_ols = Solve_OLS(X,y)\n",
    "w1_rr = Solve_RR(X,y,lambda_=1.0)\n",
    "mse_w1_ols = Compute_MSE(X,y,w1_ols)\n",
    "mse_w1_rr = Compute_MSE(X,y,w1_rr)\n",
    "print(\"MSE for w1_ols on D_1_train:\", mse_w1_ols)\n",
    "print(\"MSE for w1_rr on D_1_train:\", mse_w1_rr)\n",
    "print(w1_ols,w1_rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deliverables: \n",
    "\n",
    "3. Report MSE on Dtrain2 . Attach w2_ols and w2_rr as csv files named w_ols_[five-digit-srnumber].csv and w_rr_[five-digit-srnumber].csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for w2_ols on D_2_train: [7115.79566132]\n",
      "MSE for w2_rr on D_2_train: [2.90381334]\n",
      "Saved weights to w_ols_23627.csv and w_rr_23627.csv\n"
     ]
    }
   ],
   "source": [
    "X2, y2 = D_2_train\n",
    "mse_w2_ols = Compute_MSE(X2, y2, w2_ols)\n",
    "mse_w2_rr = Compute_MSE(X2, y2, w2_rr)\n",
    "\n",
    "# Print MSE for reporting in PDF\n",
    "print(\"MSE for w2_ols on D_2_train:\", mse_w2_ols)\n",
    "print(\"MSE for w2_rr on D_2_train:\", mse_w2_rr)\n",
    "\n",
    "# Save weights to CSV files\n",
    "srn = 23627\n",
    "np.savetxt(f\"w_ols_{srn}.csv\", w2_ols, delimiter=\",\")\n",
    "np.savetxt(f\"w_rr_{srn}.csv\", w2_rr, delimiter=\",\")\n",
    "print(f\"Saved weights to w_ols_{srn}.csv and w_rr_{srn}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 : Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned stock ticker: MRK\n",
      "Total number of days: 1258\n",
      "\n",
      "Data split for t = 7:\n",
      "  X_train shape: (625, 7)\n",
      "  y_train shape: (625,)\n",
      "  X_test shape: (626, 7)\n",
      "  y_test shape: (626,)\n",
      "\n",
      "Data split for t = 30:\n",
      "  X_train shape: (614, 30)\n",
      "  y_train shape: (614,)\n",
      "  X_test shape: (614, 30)\n",
      "  y_test shape: (614,)\n",
      "\n",
      "Data split for t = 90:\n",
      "  X_train shape: (584, 90)\n",
      "  y_train shape: (584,)\n",
      "  X_test shape: (584, 90)\n",
      "  y_test shape: (584,)\n"
     ]
    }
   ],
   "source": [
    "import Oracle_Assignment_2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Query the oracle to get the stock ticker\n",
    "Stock_Name = Oracle_Assignment_2.q3_stocknet(23627)\n",
    "print(f\"Assigned stock ticker: {Stock_Name}\")  # Returns MRK\n",
    "\n",
    "# Step 2: Load the stock data from the CSV file\n",
    "# Assuming the stocknet-dataset has been cloned to the current directory\n",
    "csv_path = f\"MRK.csv\"\n",
    "stock_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Step 3: Extract closing prices and normalize\n",
    "# Extract the 'Close' column\n",
    "closing_prices = stock_data['Close'].values  # Shape: (N,)\n",
    "\n",
    "# Normalize the closing prices using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "closing_prices_normalized = scaler.fit_transform(closing_prices.reshape(-1, 1)).flatten()\n",
    "N = len(closing_prices_normalized)  # Total number of days\n",
    "print(f\"Total number of days: {N}\")\n",
    "\n",
    "# Step 4 & 5: Create feature matrix X and labels y for each t in {7, 30, 90}\n",
    "data_splits = {}\n",
    "for t in [7, 30, 90]:\n",
    "    # Create X: Each row contains t consecutive days\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(N - t):\n",
    "        # Row i: closing prices from day i to day i+t-1\n",
    "        X.append(closing_prices_normalized[i:i+t])\n",
    "        # Label for row i: closing price on day i+t\n",
    "        y.append(closing_prices_normalized[i+t])\n",
    "    \n",
    "    X = np.array(X)  # Shape: (N-t, t)\n",
    "    y = np.array(y)  # Shape: (N-t,)\n",
    "    \n",
    "    # Step 6: Split into train and test sets (first half for training, second half for testing)\n",
    "    split_idx = (N - t) // 2\n",
    "    X_train = X[:split_idx]  # Shape: (split_idx, t)\n",
    "    y_train = y[:split_idx]  # Shape: (split_idx,)\n",
    "    X_test = X[split_idx:]   # Shape: (N-t-split_idx, t)\n",
    "    y_test = y[split_idx:]   # Shape: (N-t-split_idx,)\n",
    "    \n",
    "    # Store the data split\n",
    "    data_splits[t] = {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'scaler': scaler  # Save the scaler for denormalization later\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nData split for t = {t}:\")\n",
    "    print(f\"  X_train shape: {X_train.shape}\")\n",
    "    print(f\"  y_train shape: {y_train.shape}\")\n",
    "    print(f\"  X_test shape: {X_test.shape}\")\n",
    "    print(f\"  y_test shape: {y_test.shape}\")\n",
    "\n",
    "# The data_splits dictionary now contains the preprocessed data for each t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the following SVRs using the train set for t ∈{7,30,90}:\n",
    "\n",
    "1. Solve the dual of the slack linear support vector regression using cvxopt\n",
    "\n",
    "\n",
    "2. Solve the dual of the kernelized support vector regression using the RBF kernel for γ = [1,0.1,0.01,0.001]\n",
    "using cvxopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "class SVR:\n",
    "    \"\"\"A class to train Support Vector Regression (SVR) models using the dual formulation with cvxopt.\"\"\"\n",
    "    \n",
    "    def __init__(self, epsilon=0.1, C=1.0):\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.C = C\n",
    "        self.models = {}  # Store trained models for each t and gamma\n",
    "\n",
    "    def rbf_kernel(self, X1, X2, gamma):\n",
    "\n",
    "        N1 = len(X1)\n",
    "        N2 = len(X2)\n",
    "        K = np.zeros((N1, N2))\n",
    "        for i in range(N1):\n",
    "            for j in range(N2):\n",
    "                diff = X1[i] - X2[j]\n",
    "                K[i, j] = np.exp(-gamma * np.sum(diff ** 2))\n",
    "        return K\n",
    "\n",
    "    def train_linear_svr(self, X_train, y_train):\n",
    "        N, t = X_train.shape\n",
    "        K = X_train @ X_train.T  # Linear kernel: K = X @ X.T\n",
    "\n",
    "        # Dual Formulation Setup\n",
    "        P = np.block([[K, -K], [-K, K]])\n",
    "        P = matrix(P)\n",
    "\n",
    "        q = self.epsilon * np.ones(2 * N)\n",
    "        q[:N] -= y_train\n",
    "        q[N:] += y_train\n",
    "        q = matrix(q)\n",
    "\n",
    "        A = np.hstack([np.ones(N), -np.ones(N)])\n",
    "        A = matrix(A, (1, 2 * N))\n",
    "        b = matrix(0.0)\n",
    "\n",
    "        G = np.vstack([-np.eye(2 * N), np.eye(2 * N)])\n",
    "        h = np.hstack([np.zeros(2 * N), self.C * np.ones(2 * N)])\n",
    "        G = matrix(G)\n",
    "        h = matrix(h)\n",
    "\n",
    "        solvers.options['show_progress'] = False\n",
    "        solution = solvers.qp(P, q, G, h, A, b)\n",
    "        z = np.array(solution['x']).flatten()\n",
    "\n",
    "        alphas = z[:N]\n",
    "        alphas_star = z[N:]\n",
    "\n",
    "        # Compute w (weights) using all support vectors (nonzero alphas or alphas_star)\n",
    "        w = np.sum((alphas - alphas_star)[:, np.newaxis] * X_train, axis=0)\n",
    "\n",
    "        # Identify all support vectors (alpha_i > 0 or alpha_i* > 0)\n",
    "        support_indices = np.where((alphas > 1e-5) | (alphas_star > 1e-5))[0]\n",
    "\n",
    "        # For b calculation, use non-bounded support vectors (0 < alpha_i < C or 0 < alpha_i* < C)\n",
    "        non_bounded_indices = np.where(\n",
    "            ((alphas > 1e-5) & (alphas < self.C - 1e-5)) |\n",
    "            ((alphas_star > 1e-5) & (alphas_star < self.C - 1e-5))\n",
    "        )[0]\n",
    "\n",
    "        b_values = []\n",
    "        for i in non_bounded_indices:\n",
    "            if alphas[i] > 1e-5:  # alpha_i > 0 (and alpha_i* = 0 due to constraint)\n",
    "                b_i = y_train[i] - np.dot(w, X_train[i]) - self.epsilon\n",
    "            elif alphas_star[i] > 1e-5:  # alpha_i* > 0 (and alpha_i = 0)\n",
    "                b_i = y_train[i] - np.dot(w, X_train[i]) + self.epsilon\n",
    "            b_values.append(b_i)\n",
    "\n",
    "        b = np.mean(b_values) if b_values else 0.0\n",
    "\n",
    "        return w, b, alphas, alphas_star\n",
    "\n",
    "    def train_rbf_svr(self, X_train, y_train, gamma):\n",
    "        N = X_train.shape[0]\n",
    "        K = self.rbf_kernel(X_train, X_train, gamma)\n",
    "\n",
    "        # Dual Formulation Setup\n",
    "        P = np.block([[K, -K], [-K, K]])\n",
    "        P = matrix(P)\n",
    "\n",
    "        q = self.epsilon * np.ones(2 * N)\n",
    "        q[:N] -= y_train\n",
    "        q[N:] += y_train\n",
    "        q = matrix(q)\n",
    "\n",
    "        A = np.hstack([np.ones(N), -np.ones(N)])\n",
    "        A = matrix(A, (1, 2 * N))\n",
    "        b = matrix(0.0)\n",
    "\n",
    "        G = np.vstack([-np.eye(2 * N), np.eye(2 * N)])\n",
    "        h = np.hstack([np.zeros(2 * N), self.C * np.ones(2 * N)])\n",
    "        G = matrix(G)\n",
    "        h = matrix(h)\n",
    "\n",
    "        solvers.options['show_progress'] = False\n",
    "        solution = solvers.qp(P, q, G, h, A, b)\n",
    "        z = np.array(solution['x']).flatten()\n",
    "\n",
    "        alphas = z[:N]\n",
    "        alphas_star = z[N:]\n",
    "\n",
    "        # Identify all support vectors (alpha_i > 0 or alpha_i* > 0)\n",
    "        support_indices = np.where((alphas > 1e-5) | (alphas_star > 1e-5))[0]\n",
    "\n",
    "        # For b calculation, use non-bounded support vectors (0 < alpha_i < C or 0 < alpha_i* < C)\n",
    "        non_bounded_indices = np.where(\n",
    "            ((alphas > 1e-5) & (alphas < self.C - 1e-5)) |\n",
    "            ((alphas_star > 1e-5) & (alphas_star < self.C - 1e-5))\n",
    "        )[0]\n",
    "\n",
    "        b_values = []\n",
    "        for i in non_bounded_indices:\n",
    "            kernel_row = K[i]\n",
    "            kernel_sum = np.sum((alphas - alphas_star) * kernel_row)\n",
    "            if alphas[i] > 1e-5:  # alpha_i > 0 (and alpha_i* = 0 due to constraint)\n",
    "                b_i = y_train[i] - kernel_sum - self.epsilon\n",
    "            elif alphas_star[i] > 1e-5:  # alpha_i* > 0 (and alpha_i = 0)\n",
    "                b_i = y_train[i] - kernel_sum + self.epsilon\n",
    "            b_values.append(b_i)\n",
    "\n",
    "        b = np.mean(b_values) if b_values else 0.0\n",
    "\n",
    "        return alphas, alphas_star, b\n",
    "\n",
    "    def task_1(self, data_splits):\n",
    "        for t in [7, 30, 90]:\n",
    "            X_train = data_splits[t]['X_train']\n",
    "            y_train = data_splits[t]['y_train']\n",
    "            \n",
    "            w, b, alphas, alphas_star = self.train_linear_svr(X_train, y_train)\n",
    "            \n",
    "            # Identify support vectors (alpha_i > 0 or alpha_i* > 0)\n",
    "            support_indices = np.where((alphas > 1e-5) | (alphas_star > 1e-5))[0]\n",
    "            num_support_vectors = len(support_indices)\n",
    "            \n",
    "            # Store the model\n",
    "            if t not in self.models:\n",
    "                self.models[t] = {}\n",
    "            self.models[t]['linear'] = {\n",
    "                'w': w,\n",
    "                'b': b,\n",
    "                'alphas': alphas,\n",
    "                'alphas_star': alphas_star,\n",
    "                'support_indices': support_indices,  # Store indices for reference\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train\n",
    "            }\n",
    "            \n",
    "            print(f\"Trained Linear SVR for t = {t}:\")\n",
    "            print(f\"  Weight vector shape: {w.shape}\")\n",
    "            print(f\"  Bias term b: {b:.4f}\")\n",
    "            print(f\"  Number of support vectors: {num_support_vectors}\\n\")\n",
    "\n",
    "    def task_2(self, data_splits):\n",
    "        gamma_values = [1, 0.1, 0.01, 0.001]\n",
    "        print(\"Task 2: Training RBF SVR Models\\n\")\n",
    "        for t in [7, 30, 90]:\n",
    "            X_train = data_splits[t]['X_train']\n",
    "            y_train = data_splits[t]['y_train']\n",
    "            \n",
    "            for gamma in gamma_values:\n",
    "                alphas, alphas_star, b = self.train_rbf_svr(X_train, y_train, gamma)\n",
    "                \n",
    "                # Identify support vectors (alpha_i > 0 or alpha_i* > 0)\n",
    "                support_indices = np.where((alphas > 1e-5) | (alphas_star > 1e-5))[0]\n",
    "                num_support_vectors = len(support_indices)\n",
    "                \n",
    "                # Store the model\n",
    "                if t not in self.models:\n",
    "                    self.models[t] = {}\n",
    "                self.models[t][gamma] = {\n",
    "                    'alphas': alphas,\n",
    "                    'alphas_star': alphas_star,\n",
    "                    'b': b,\n",
    "                    'support_indices': support_indices,  # Store indices for reference\n",
    "                    'X_train': X_train,\n",
    "                    'y_train': y_train\n",
    "                }\n",
    "                \n",
    "                print(f\"Trained RBF SVR for t = {t}, gamma = {gamma}:\")\n",
    "                print(f\"  Number of support vectors: {num_support_vectors}\")\n",
    "                print(f\"  Bias term b: {b:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deliverables :\n",
    "\n",
    "For each SVR trained, plot a graph on the test set containing the following:\n",
    "1. Predicted closing price value.\n",
    "2. Actual closing price value.\n",
    "3. Average price on the previous t days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Linear SVR for t = 7:\n",
      "  Weight vector shape: (7,)\n",
      "  Bias term b: 0.0004\n",
      "  Number of support vectors: 121\n",
      "\n",
      "Trained Linear SVR for t = 30:\n",
      "  Weight vector shape: (30,)\n",
      "  Bias term b: 0.0075\n",
      "  Number of support vectors: 137\n",
      "\n",
      "Trained Linear SVR for t = 90:\n",
      "  Weight vector shape: (90,)\n",
      "  Bias term b: 0.0144\n",
      "  Number of support vectors: 169\n",
      "\n",
      "Task 2: Training RBF SVR Models\n",
      "\n",
      "Trained RBF SVR for t = 7, gamma = 1:\n",
      "  Number of support vectors: 158\n",
      "  Bias term b: -0.3682\n",
      "\n",
      "Trained RBF SVR for t = 7, gamma = 0.1:\n",
      "  Number of support vectors: 142\n",
      "  Bias term b: -0.4618\n",
      "\n",
      "Trained RBF SVR for t = 7, gamma = 0.01:\n",
      "  Number of support vectors: 178\n",
      "  Bias term b: -0.6180\n",
      "\n",
      "Trained RBF SVR for t = 7, gamma = 0.001:\n",
      "  Number of support vectors: 246\n",
      "  Bias term b: 0.0000\n",
      "\n",
      "Trained RBF SVR for t = 30, gamma = 1:\n",
      "  Number of support vectors: 259\n",
      "  Bias term b: -0.1084\n",
      "\n",
      "Trained RBF SVR for t = 30, gamma = 0.1:\n",
      "  Number of support vectors: 165\n",
      "  Bias term b: -0.1637\n",
      "\n",
      "Trained RBF SVR for t = 30, gamma = 0.01:\n",
      "  Number of support vectors: 191\n",
      "  Bias term b: -0.3395\n",
      "\n",
      "Trained RBF SVR for t = 30, gamma = 0.001:\n",
      "  Number of support vectors: 288\n",
      "  Bias term b: -0.8986\n",
      "\n",
      "Trained RBF SVR for t = 90, gamma = 1:\n",
      "  Number of support vectors: 515\n",
      "  Bias term b: -0.0673\n",
      "\n",
      "Trained RBF SVR for t = 90, gamma = 0.1:\n",
      "  Number of support vectors: 151\n",
      "  Bias term b: -0.1156\n",
      "\n",
      "Trained RBF SVR for t = 90, gamma = 0.01:\n",
      "  Number of support vectors: 206\n",
      "  Bias term b: -0.1598\n",
      "\n",
      "Trained RBF SVR for t = 90, gamma = 0.001:\n",
      "  Number of support vectors: 280\n",
      "  Bias term b: -0.5314\n",
      "\n",
      "Plots generated for all SVR models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rbf_kernel(X1, X2, gamma):\n",
    "    N1, t = X1.shape\n",
    "    N2, _ = X2.shape\n",
    "    K = np.zeros((N1, N2))\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "            diff = X1[i] - X2[j]\n",
    "            K[i, j] = np.exp(-gamma * np.sum(diff ** 2))\n",
    "    return K\n",
    "\n",
    "def predict_linear(X, model):\n",
    "    w = model['w']\n",
    "    b = model['b']\n",
    "    y_pred = X @ w + b\n",
    "    return y_pred\n",
    "\n",
    "def predict_rbf(X, model, gamma):\n",
    "    alphas = model['alphas']\n",
    "    alphas_star = model['alphas_star']\n",
    "    b = model['b']\n",
    "    X_train = model['X_train']\n",
    "    K = rbf_kernel(X, X_train, gamma)\n",
    "    y_pred = np.sum((alphas - alphas_star) * K, axis=1) + b\n",
    "    return y_pred\n",
    "\n",
    "def compute_average_prices(X):\n",
    "    return np.mean(X, axis=1)\n",
    "\n",
    "def plot_results(data_splits, svr_trainer):\n",
    "    gamma_values = [1, 0.1, 0.01, 0.001]\n",
    "    \n",
    "    for t in [7, 30, 90]:\n",
    "        X_test = data_splits[t]['X_test']\n",
    "        y_test = data_splits[t]['y_test']\n",
    "        scaler = data_splits[t]['scaler']\n",
    "        \n",
    "        # Denormalize the actual prices\n",
    "        y_test_denorm = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Compute the average prices and denormalize\n",
    "        avg_prices = compute_average_prices(X_test)\n",
    "        avg_prices_denorm = scaler.inverse_transform(avg_prices.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Plot for Linear SVR\n",
    "        model_linear = svr_trainer.models[t]['linear']\n",
    "        y_pred_linear = predict_linear(X_test, model_linear)\n",
    "        y_pred_linear_denorm = scaler.inverse_transform(y_pred_linear.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(y_pred_linear_denorm, label='Predicted (Linear SVR)', color='blue')\n",
    "        plt.plot(y_test_denorm, label='Actual', color='green')\n",
    "        plt.plot(avg_prices_denorm, label=f'Average of previous {t} days', color='orange', linestyle='--')\n",
    "        plt.title(f'Linear SVR (t = {t})')\n",
    "        plt.xlabel('Test Sample Index')\n",
    "        plt.ylabel('Closing Price (USD)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f'linear_svr_t_{t}.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot for each RBF SVR model\n",
    "        for gamma in gamma_values:\n",
    "            model_rbf = svr_trainer.models[t][gamma]\n",
    "            y_pred_rbf = predict_rbf(X_test, model_rbf, gamma)\n",
    "            y_pred_rbf_denorm = scaler.inverse_transform(y_pred_rbf.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(y_pred_rbf_denorm, label=f'Predicted (RBF SVR, gamma={gamma})', color='blue')\n",
    "            plt.plot(y_test_denorm, label='Actual', color='green')\n",
    "            plt.plot(avg_prices_denorm, label=f'Average of previous {t} days', color='orange', linestyle='--')\n",
    "            plt.title(f'RBF SVR (t = {t}, gamma = {gamma})')\n",
    "            plt.xlabel('Test Sample Index')\n",
    "            plt.ylabel('Closing Price (USD)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f'rbf_svr_t_{t}_gamma_{gamma}.png')\n",
    "            plt.close()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume data_splits is available from preprocessing\n",
    "    svr_trainer = SVR(epsilon=0.1, C=1.0)\n",
    "    svr_trainer.task_1(data_splits)\n",
    "    svr_trainer.task_2(data_splits)\n",
    "    plot_results(data_splits, svr_trainer)\n",
    "    print(\"Plots generated for all SVR models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
